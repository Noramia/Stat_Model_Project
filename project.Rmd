---
title: "SM3_Project"
author: "Shingyan Kwong"
date: "May 13, 2018"
output: html_document
---
```{r,echo=FALSE}
library(broom)
library(MASS)
library(magrittr)
```



#Part A.

#1. 
```{r,echo=FALSE}
child<-read.table("Child_Height.txt",header=T)
```


```{r}
pairs(~Height+Weight+Length,data=child)
```

There is evidence of a strong, positive linear relationship between  length and the two predictor variables, height and weight. The associated correlation coefficients are 0.881 and 0.894 respectively. There is also a strong, positive linear relationship between height and weight. This suggests that the two predictors may be dependent one another.


#2. 

```{r}
lm1<-lm(Length~Height+Weight, data=child)
lm2<-lm(Length~Height, data=child)
lm3<-lm(Length~Weight, data=child)

```


#3. 

The model assumptions which may be checked via diagnostic plots are as follows. 

Linearity: Check the residuals vs fitted and the residuals vs predictor plots. Linearity is reasonable if random scatter above and below the 0 line is observed. 

Constant Variance: Check scale location plot. Homoscedacity is reasonable if constant variance of residuals is observed across the scale location plot. 

Normality: Check normal qq plot. Normality is reasonable if most points between -2 and 2 are on/close to the diagonal line. 

#4. 

#Full model

```{r}
par(mfrow=c(2,2))
plot(lm1)
```

```{r}
par(mfrow=c(1,2))
res1<-rstudent(lm1)
fit<-fitted(lm1)
plot(child$Height,res1,main="Residuals vs height",pch=20)
abline(0,0,col="red")
plot(child$Weight,res1,main="Residuals vs weight",pch=20)
abline(0,0,col="red")

```


Linearity: Given the small number of data points available, roughly random scatter is observed in the residual vs fitted and residual vs predictor plots. There is a couple of high residual points but it is not too bad. Linearity is reasonable. 

Constant variance: Scale location plots appear to show heteroscedacity. Constant variance is not reasonable.  

Normality: There is some minor departure from normality in the beginning and the tails of the standardized residuals. Overall the points are fairly close to the diagonal line. Normality is reasonable. 

Leverage: There are 2 data points in the zone of danger. These high leverage points are having a disproportionate effect on the model. 

#Model with Weight only

```{r}
par(mfrow=c(2,2))
plot(lm2)
```

```{r}
par(mfrow=c(1,2))
res1<-rstudent(lm2)
fit<-fitted(lm2)
plot(child$Height,res1,main="Residuals vs height",pch=20)
abline(0,0,col="red")
plot(child$Weight,res1,main="Residuals vs weight",pch=20)
abline(0,0,col="red")
```


Linearity: Non-random scatter observed in residual vs fitted and residual vs predictor plots. Linearity is not reasonable. 

Constant Variance: Variance appears to increase for the middle fitted values and then decrease again. Constant variance is not reasonable. 

Normality: There are several points deviating from the diagonal line on the normal qq plot. Normality is not reasonable. 

Leverage: There is one point with high leverage. 

#Model with Height only

```{r}
par(mfrow=c(2,2))
plot(lm3)
```

```{r}
par(mfrow=c(1,2))
res1<-rstudent(lm3)
fit<-fitted(lm3)
plot(child$Height,res1,main="Residuals vs height",pch=20)
abline(0,0,col="red")
plot(child$Weight,res1,main="Residuals vs weight",pch=20)
abline(0,0,col="red")

```

Linearity: Rough random scatter in observed in residual vs fitted and residual vs predictor plots. The fitted plot shows some evidence of curvature but overall it is acceptable. Linearity is reasonable. 

Constant Variance: Variance is roughly constant across the scale location plot. Constant variance is reasonable. 

Normality: Most points are close to the diagonal line except 2. Normality is reasonable. 

Leverage: There is one data point with high leverage. 

#5. Comparison of the three models

```{r}
summary(lm1)
```

```{r}
summary(lm2)

```


```{r}
summary(lm3)

```

(a)

In the full model, neither predictor variables is statistically significant (at the 0.05 level), and the numerical values of the two coefficients are both smaller than those of the single predictor models.

(b)

Full model:

Holding height constant, the full model predicts that an increase of of 1kg will on average increase the length of the cathetar by 0.42081cm. 

Weight only model:

Without regard for height, this model predicts that an increase of 1kg will on average increase the cathetar length by 0.61136cm. 

#6

(a) We construct the model matrices for the height only and weight only models. 

```{r,echo=FALSE}
lm2 <- lm(Length ~ Height, data = child)
lm3 <- lm(Length ~ Weight, data = child)
M2 <- model.matrix(lm2)
M3 <-  model.matrix(lm3)
M2
M3
```

L_1 is the space spanned by the columns of M2. 
L_2 is the space spanned by the columns of M3. 

The intersection of the two subspaces is the intercept column. 

$$L_1 \cap L2 = span {(1,1,1,1,1,1,1,1,1,1,1,1) }.$$

(b) WARNING: INCOMPLETE

We find an orthogonal basis for L_1 and L_2 by applying the Gram-Schmidt process (without the normalizing step). 

```{r}
## Gram Schmidt:
one <- c(1,1,1,1,1,1,1,1,1,1,1,1) # intercept vector
x1 <- M2[,2] # vector of height values
x2 <- M3[,2] # vector of weight values
norm_vec <- function(x) sqrt(as.numeric(t(x) %*% x))
```


```{r}
v1 <- one / norm_vec(one)
v2_ <- x1 - as.numeric((t(x1) %*% v1)) * v1
v2 <- v2_ / norm_vec(v2_)
```


then L_1 = {v1, v2} 

```{r}
w1 <- one / norm_vec(one)
w2_ <- x2 - as.numeric((t(x2) %*% w1)) * w1
w2 <- w2_ / norm_vec(w2_)
```


# then L_2 = {w1, w2}


$$ L_1 \cap ({L_1 \cap L_2})^{perp} : $$
$$ L_2 \cap ({L_1 \cap L_2})^{perp} :$$

(c)

We compute the angle between the two spaces in (b) as follows. 

```{r}
dot <- t(v2) %*% (w2)
norm_v2 <- norm_vec(v2)
norm_w2 <- norm_vec(w2)
theta <- acos(dot/(norm_v2 * norm_w2))
theta
theta_deg <- theta * 180/pi
```

The angle is not pi indicating that the two spaces are NOT orthogonal. This suggests that height and weight are NOT independent. In fact they are fairly correlated. 

#7

Picking a model. 

_______
#6. Linear spaces. Anthony will rewrite this later

Comparing these three models, lm3 (length~weight) is better than others. From the analysis of diagnostic plots of these three models, the four assumptions in lm3 can be considered as the most reasonable. Moreover, the angle between two spaces is approximately equal to two, which means they are not orthogonal to each other. Furthermore, there exists linear relationship between the two predictor variables (height and weight) with correlation 0.961. Overall, weight as the predictor variable and length as the response variables is the most appropriate model.

______


# Part B


## Introduction

In this section we obtain a predictive model for mammographic mass severity, a measure of the status of mammographic mass lesions, on a scale from 0 to 1, where 0 is assigned to a benign tumor, and 1 is assigned to a malignant tumor. Interest in this analysis arises from there being a low predicitve value of breast biopsy from mammograms. This low predictive value has been found to lead to approximately 70% of unnessessary biopsies of benign tumors. Analysis is performed on the dataset "mammo", containing the true status of 961 mammographic mass lesions, with the response variable severity as described. Four response variables are considered:

**Age** - the patient's age in years;

**Shape** - a factor variable with four levels: 1 for round, 2 for oval, 3 for lobular, and 4 for irregular;

**Margin** - a factor varaible with five levels: 1 for circumscribed, 2 for microlobulated, 3 for obscured, 4 for ill-defined, and 5 for spiculated;

**Density** - a factor with four levels: 1 for high, 2 for iso, 3 for low, and 4 for fat-containing.


**This introduction should probably be reworked but I this hope is a good starting point**


##Data Entry and Cleaning
First, we enter the data and define any values which are assigned question marks to be missing values:

```{r}
mammo <- read.csv("mammo.txt", header=TRUE, na.strings = "?")
```

We then note that BI.RADS is not a predictor variable, and remove it from our analysis:

```{r}
mammo <- dplyr::select(mammo, Age, Shape, Margin, Density, Severity)
```

We can now check the variable types for the data:

```{r}
str(mammo)
```

We note that Shape, Margin, Density and Severity should all be factor variables, and as such convert them:

```{r}
mammo$Shape <- as.factor(mammo$Shape)
mammo$Margin <- as.factor(mammo$Margin)
mammo$Density <- as.factor(mammo$Density)
mammo$Severity <- as.factor(mammo$Severity)
```

We now see that all of the data types are correct:

```{r}
str(mammo)
```


## Data Visualisations and Data Summaries

To visualise the data, we first produce summary statisitics for the dataset as a whole, and for each individual variable:

```{r}
summary(mammo$Age)
print(" ")
summary(mammo$Shape)
print(" ")
summary(mammo$Margin)
print(" ")
summary(mammo$Density)
print(" ")
summary(mammo$Severity)
```

We also create a pairwise scatterplot to observe the relationships between indivisual variables:

```{r, fig.cap = "Pairwise scatterplot of Mammographic Mass Severity Data"}
pairs(mammo)
```

There appears to be a weak,possibly linear, positive relationship between Age and Severity. There are no observable relationships between Severity and the other predictors. 

## Model Fitting and Model Selection

We now fit a logistic linear model (M1) to the data, with Severity as the response variable, and Age, Shape, Margin and Density as the predictor variables:

```{r}
full.glm <- glm(Severity ~ Age+Shape+Margin+Density, data = mammo, family = "binomial")
summary(full.glm)
```

The p-values for all levels of Density are above 0.05, indicating that it is not statistically significant at the 0.05 level. This suggests that removing Density may lead to a more parsimonious model. We first construct the model without Density (asm.glm).

```{r}
asm.glm <- glm(Severity ~ Age+Shape+Margin, data = mammo, family = "binomial")
summary(asm.glm)
```

We conduct an log-likelihood ratio test comparing asm.glm and full.glm.

G2=deviance(asm)-deviance(full)

```{r}
G<-773.89-726.96
G
```

df=p-p_o

G~chisq(df=)